---
layout: post
title: "B-trees"
date: 2022-08-08
---


# Introduction
In this post, I will explain what are B-trees, data structures commonly used to implement database indexes. Understanding them will later make understanding the behavior and performance of indexes easier.

Before we get to B-trees, we will start with something more basic, and progress to more advanced data structures to show what problems they solve. 

## Binary search trees
One of the most basic data structures covered in every algorithm course is a binary search tree. 
BST is either a null node (an empty node), or a node containing a value and two child nodes (left and right subtrees), where the value in the left child node has to be smaller than its parent, and the value in the right child node has to be greater than its parent. 

An example of a BST is shown below.
![BST](/assets/images/2022-08-08/BSTtrees.png)


If a BST is balanced, its height is roughly equal to log<sub>2</sub>(n), where n is the number of nodes in the tree. In that case, all basic operations - insert, delete, search - have an average computational complexity of O(log(n)). 
However, the problem with BST is that if it is not balanced, its performance may degrade dramatically. The worst-case scenario is that every node has only one child node. In that case, a tree degenerates to a linked list, and all basic operations have a computational complexity of O(n). 

An example of such BST.
![BST](/assets/images/2022-08-08/BSTtrees2.png)


To give a concrete example: a balanced tree with 1000 nodes has a height equal to 10, whereas a tree degenerated to a linked list has a height of 1000. Since performance is proportional to tree height, all operations will on average be 100 times slower! To make things worse, this happens in practice when values inserted into a tree are sorted, which is a common case if values are automatically generated identifiers. 


## Self-balancing trees
To address issues with BSTs, we can use self-balancing trees. The two most popular examples of such data structures are red-black trees and AVL trees. The basic idea in both cases is to use operations called "tree rotations" to rebalance the tree after inserting or deleting a node. They differ in how exactly they do that, and what guarantees they provide. 

A red-black tree is a BST that must satisfy a few additional properties:
1. Every node is marked with a "color", either red or black.
2. All NULL nodes are black.
3. A red node cannot have a red child.
4. Any path from the root node to any of the NULL nodes goes through the same number of black nodes

An example of a red-black tree is shown below
![BST](/assets/images/2022-08-08/RBtrees.png)

This tree was created by inserting the same values previously shown BSTs contain, sorted in ascending order. 
As you can see, the tree is not perfectly balanced, but the longest path from the root to a leaf node (node 11 to nodes 27 and 35) is less than two times longer than the shortest path from the root to a leaf node (node 11 to 2 and 7).
Red-black trees work well as an in-memory data structure.


## B-trees
Red-Black trees are an improvement over BSTs, but they still have some serious issues when applied to databases:
- For big trees (with millions of nodes, which is a realistic scenario in many databases) the height of the tree is still relatively big. For 1 milion we get h = log<sub>2</sub>(1 000 000) ~= 20. 
- Since each node stores just one value, they are not optimal for storage dealing with blocks of memory, like a hard drive. 

Imagine the following scenario: we want to search for a value in a tree having 1 million nodes. If the tree is stored on a hard drive (like DB indexes are), we will need to:
- load a block of data from the disk into the RAM, then into the CPU cache
- get the value of a node we want to compare the searched value with and perform a comparison
- get a subtree to recursively search in
- possibly load another block of memory containing the subtree
- repeat 20 times if the tree is perfectly balanced, more if it's not

Since loading a block of memory from the disk into RAM is orders of magnitude slower than comparing two values, it would be beneficial if we could perform as many comparisons as possible for each block of data loaded into the memory. 

The first issue is solved by increasing the branching factor. BF defines how many child nodes a parent node can have. For binary trees, it's equal to 2, because each node can have up to 2 child nodes. For B-trees, it can be much bigger, in practice even up to a few hundred. A B-tree with BF equal to 100 and 1 million nodes will have a height of log<sub>100</sub>(1 000 000) = 3. A tree with 10 billion nodes will have a height of log<sub>100</sub>(10 000 000 000) = 5. So in practice, a tree with such branching factor will never have a height greater than that. 

The last optimization is that leaf nodes are linked to each other, essentially forming a linked list. This is useful for range queries: we can find the first item belonging to a range by traversing down the tree, then find the rest by iterating through the nodes like a linked list, without the need to go back up the tree structure again. 


An example of a B-tree with branching factor of 3
![BST](/assets/images/2022-08-08/Btrees.png)


# Summary
In this post, I covered the basics of B-tree, a data structure commonly used to implement indexes in databases. Understanding how they work makes understanding many indexes-related topics a lot easier. In the next post, I will explain what are index fragmentation and page fullness. 

# References
- [Binary search trees](https://en.wikipedia.org/wiki/Binary_search_tree)
- [Red-black trees](https://en.wikipedia.org/wiki/Red%E2%80%93black_tree)
- [B-trees](https://en.wikipedia.org/wiki/B-tree)

- [Red-black trees visualization](https://www.cs.usfca.edu/~galles/visualization/RedBlack.html)
- [B-tree visualization](https://www.cs.usfca.edu/~galles/visualization/BTree.html)